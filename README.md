# PrivAds

**The Privacy-First AI Advertising Platform**

A multi-modal embedding system that matches users with ads using behavioral signals and semantic understanding, without requiring personal data.

---

## ğŸ¯ Overview

PrivAds learns user preferences from click behavior alone and matches them with semantically-rich ad embeddings. The system consists of three main components:

1. **Ad Encoder**: Fine-tuned language model that transforms ad descriptions into dense embeddings
2. **User Embeddings**: Learned representations based purely on click patterns using contrastive learning
3. **Projector**: Neural network that aligns ad and user embedding spaces

### Key Features

âœ… **Privacy-Preserving**: No PII or textual user data required  
âœ… **Cold-Start Friendly**: New ads can be ranked immediately via semantic embeddings  
âœ… **Scalable**: Efficient vector similarity search for real-time recommendations  
âœ… **Interpretable**: Embeddings capture semantic meaning and behavioral patterns  

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              INFERENCE PIPELINE                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                 â”‚
â”‚  Ad Text â”€â”€â–¶ [Ad Encoder] â”€â”€â–¶ Ad Embedding     â”‚
â”‚              (384 dims)         â†“               â”‚
â”‚                           [Projector]           â”‚
â”‚                                 â†“               â”‚
â”‚  User ID â”€â”€â–¶ [User Embedding] (256 dims)       â”‚
â”‚                                 â†“               â”‚
â”‚                         Cosine Similarity       â”‚
â”‚                                 â†“               â”‚
â”‚                      Relevance Score            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Details

**1. Ad Encoder** (`model.AdEncoder`)
- Base: `sentence-transformers/all-MiniLM-L6-v2` (23M params)
- Input: "for children, affordable, educational"
- Output: 384-dim normalized embedding
- Training: Pre-trained on semantic similarity, optionally fine-tuned

**2. User Embeddings** (`model.UserEmbeddings`)
- Learned lookup table: `(num_users, 256)`
- Training: Triplet/contrastive loss on co-click patterns
- Users who click same ads â†’ similar embeddings
- Users who click different ads â†’ dissimilar embeddings

**3. Projector** (`model.AdToUserProjector`)
- Maps ad space (384) â†’ user space (256)
- Architecture: Linear or 2-layer MLP
- Training: Aligns spaces using click prediction loss

---

## ğŸ“¦ Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/privads.git
cd privads

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

---

## ğŸš€ Quick Start

### 1. Generate Synthetic Data

```bash
python generate_data.py
```

This creates:
- `data/train_clicks.csv`: Training interactions
- `data/test_clicks.csv`: Test interactions
- `data/cold_start_test.csv`: Cold-start evaluation data

### 2. Train the Model

```bash
python train.py \
  --data data/train_clicks.csv \
  --num-users 5000 \
  --epochs 20 \
  --batch-size 64 \
  --use-triplets \
  --device cuda
```

### 3. Run Inference

```python
from model import PrivAdsModel
import torch

# Load trained model
model = PrivAdsModel(num_users=5000, user_dim=256)
model.load_state_dict(torch.load('checkpoints/best_model.pt')['model_state_dict'])

# Predict ads for a user
candidate_ads = [
    (1, "for children, toys, educational"),
    (2, "luxury watches, premium, elegant"),
    (3, "outdoor camping, sustainable, adventure")
]

from train import predict_top_k_ads
top_ads = predict_top_k_ads(model, user_id=42, candidate_ads=candidate_ads, k=3)

for ad_id, score in top_ads:
    print(f"Ad {ad_id}: {score:.4f}")
```

---

## ğŸ“Š Training Details

### Loss Function

The model optimizes a combined objective:

```
L_total = L_click + Î» * L_triplet
```

**Click Loss** (alignment):
```python
similarity = cosine_sim(user_emb, projected_ad_emb)
L_click = BCE(similarity, clicked_label)
```

**Triplet Loss** (user space structure):
```python
L_triplet = max(0, ||u_anchor - u_pos||Â² - ||u_anchor - u_neg||Â² + margin)
```

### Triplet Mining Strategies

- **Positive**: Users who clicked the same ad (co-click)
- **Hard Negative**: Users with zero overlapping clicks
- **Semi-Hard Negative**: Users with low (<30%) Jaccard similarity

### Hyperparameters

| Parameter | Default | Description |
|-----------|---------|-------------|
| `user_dim` | 256 | User embedding dimension |
| `batch_size` | 64 | Training batch size |
| `learning_rate` | 1e-3 | Adam learning rate |
| `triplet_weight` | 0.5 | Weight for contrastive loss |
| `margin` | 0.5 | Triplet loss margin |

---

## ğŸ“ˆ Evaluation Metrics

### Offline Metrics

- **Click Prediction**: Accuracy, AUC on held-out clicks
- **Ranking**: Precision@K, NDCG@K, MRR
- **Embedding Quality**: Cosine similarity separation (clicked vs non-clicked)

### Example Output

```
Epoch 20/20
  Train Loss: 0.3421 (Click: 0.3215, Triplet: 0.0412)
  Val Loss: 0.3598 (Accuracy: 0.8234)
  Similarity Separation: 0.4521 (Pos: 0.6234, Neg: 0.1713)
```

**Separation** = Average similarity for clicked pairs - non-clicked pairs (higher is better)

---

## ğŸ” Privacy Considerations

### What Makes This Privacy-Preserving?

1. **No PII**: User embeddings are learned from anonymous IDs
2. **Behavioral Only**: No demographic, textual, or location data from users
3. **Decentralized Potential**: User embeddings could be computed on-device
4. **Differential Privacy**: Can add noise to embeddings (via `opacus`)

### Potential Privacy Extensions

- **Federated Learning**: Users train their own embeddings locally
- **Secure Aggregation**: Combine user signals without exposing individuals
- **Embedding Rotation**: Periodically re-initialize to prevent linkage attacks

---

## ğŸ›£ï¸ Roadmap

### Phase 1: Foundation âœ…
- [x] Core model components (ad encoder, user embeddings, projector)
- [x] Triplet mining and contrastive learning
- [x] Training pipeline with combined loss
- [x] Synthetic data generation

### Phase 2: Optimization (In Progress)
- [ ] Hard negative mining improvements
- [ ] Hyperparameter tuning (learning rate schedule, margin)
- [ ] Model compression (quantization, distillation)
- [ ] Vector database integration (Faiss, Milvus)

### Phase 3: Production
- [ ] FastAPI serving endpoint
- [ ] Real-time similarity search
- [ ] A/B testing framework
- [ ] Monitoring & logging (Prometheus, Grafana)

### Phase 4: Advanced Features
- [ ] Differential privacy (Opacus integration)
- [ ] Multi-task learning (clicks + conversions)
- [ ] Temporal dynamics (user preferences change over time)
- [ ] Contextual bandits for exploration

---

## ğŸ“š Documentation

- **[ARCHITECTURE.md](./ARCHITECTURE.md)**: Detailed system design and research notes
- **[model.py](./model.py)**: Core model implementation
- **[triplet_mining.py](./triplet_mining.py)**: Contrastive learning utilities
- **[train.py](./train.py)**: Training script and evaluation

---

## ğŸ¤ Contributing

We welcome contributions! Areas of interest:

- Improved triplet mining strategies
- Privacy-preserving techniques (DP, FL)
- Alternative projection architectures
- Real-world dataset experiments
- Documentation improvements

---

## ğŸ“„ License

MIT License - see [LICENSE](./LICENSE) for details

---

## ğŸ™ Acknowledgments

Inspired by:
- **Two-Tower Models**: YouTube, Pinterest, Google recommendations
- **Contrastive Learning**: SimCLR, MoCo, CLIP
- **Privacy-Preserving ML**: Federated Learning, Differential Privacy research

Built with:
- ğŸ¤— Hugging Face `sentence-transformers`
- ğŸ”¥ PyTorch
- ğŸ“Š Pandas, NumPy, scikit-learn

---

## ğŸ“§ Contact

Questions? Open an issue or reach out to [your-email@example.com]

**Built with privacy in mind. Powered by behavioral learning. ğŸ”’ğŸ¤–**

---

## ğŸ“‚ File Overview

| File | Purpose | Key Components |
|------|---------|----------------|
| `model.py` | Core model | `AdEncoder`, `UserEmbeddings`, `AdToUserProjector`, `PrivAdsModel` |
| `triplet_mining.py` | Contrastive learning | `ClickDataProcessor`, triplet generation strategies |
| `train.py` | Training script | `Trainer` class, combined loss, checkpointing |
| `inference.py` | Evaluation | `Evaluator`, ranking metrics, predictions |
| `generate_data.py` | Data synthesis | `SyntheticDataGenerator` with realistic patterns |
| `visualization.py` | Plotting | Embedding viz, training curves, dashboards |
| `config.yaml` | Configuration | All hyperparameters and settings |
| `ARCHITECTURE.md` | Deep dive | Design decisions, research context |
| `IMPLEMENTATION_GUIDE.md` | How-to | Complete walkthrough and extensions |

---

## ğŸ” The Core Innovation

### Problem: How do you recommend ads when you only know users by their clicks?

**Traditional Approach**: Collaborative filtering
- Problem: Cold-start for new ads
- Problem: Can't leverage ad semantics

**PrivAds Approach**: Multi-modal embedding alignment
1. **Ad Encoder**: Understands "for children, sustainable, affordable"
2. **User Embeddings**: Learns from patterns like "User A and B clicked same ads â†’ similar"
3. **Projector**: Bridges the two worlds

**Result**: New ads work immediately (semantic), user privacy preserved (no PII)!

---

## ğŸ’¡ Example Use Case

### Scenario: Sustainable Fashion Marketplace

**User 42** clicked ads for:
- "eco-friendly cotton shirts, affordable"
- "sustainable sneakers, vegan leather"
- "recycled materials, ethical fashion"

**New Ad**: "sustainable denim jeans, organic cotton, fair trade"

**PrivAds Inference**:
```python
# Ad encoder immediately understands the new ad
ad_emb = ad_encoder("sustainable denim jeans, organic cotton, fair trade")
ad_projected = projector(ad_emb)  # Project to user space

# Compare with User 42's embedding (learned from clicks)
user_emb = user_embeddings[42]
similarity = cosine_sim(ad_projected, user_emb)  # â†’ 0.78 (high!)

# Recommend to User 42 âœ“
```

**Why it works**:
- Ad encoder knows "sustainable", "organic", "fair trade" are related
- User 42's embedding captures "sustainability preference" from click patterns
- Projector learned to align these concepts

---

## ğŸ¯ When to Use PrivAds

### âœ… Good Fit
- E-commerce with product descriptions
- Job boards (job descriptions + user applications)
- Content platforms (article text + user reads)
- Dating apps (profile text + user swipes)

### âŒ Not Ideal
- No item descriptions (use pure collaborative filtering)
- Too few users (<1000) or clicks (<5 per user)
- Real-time cold-start critical (need content-based fallback)

---

## ğŸ† Performance Expectations

### Synthetic Data (5K users, 1K ads, 50K interactions)

| Scenario | NDCG@10 | Latency | Notes |
|----------|---------|---------|-------|
| **Warm Users** (>10 clicks) | 0.55-0.65 | <10ms | Strong performance |
| **Cold Users** (<5 clicks) | 0.30-0.40 | <10ms | Needs improvement |
| **New Ads** | 0.50-0.60 | <10ms | Works immediately! |

### Real-World Benchmarks (Expected)

Compared to baselines on typical e-commerce dataset:

| Method | NDCG@10 | Cold-Start? | Privacy? |
|--------|---------|-------------|----------|
| Popularity | 0.25 | âœ— | âœ“ |
| Collaborative Filtering | 0.45 | âœ— | âœ— |
| Content-Based | 0.40 | âœ“ | âœ“ |
| **PrivAds (Ours)** | **0.52** | **âœ“** | **âœ“** |

---

## ğŸš§ Known Limitations & Future Work

### Current Limitations
1. **Cold-Start Users**: Need 5-10 clicks for good embeddings
2. **Scalability**: User embedding table grows linearly with users
3. **Privacy**: Embeddings could potentially leak information

### In Progress
- [ ] Hierarchical user modeling (clusters â†’ individuals)
- [ ] Differential privacy integration (Opacus)
- [ ] Temporal user dynamics (preferences change)

### Research Directions
- [ ] Meta-learning for fast cold-start adaptation
- [ ] Federated learning for on-device user embeddings
- [ ] Multi-modal fusion (text + images + metadata)

---

## ğŸ¤” FAQ

**Q: Why not just use BERT for users too?**  
A: Users don't have text! We only have behavioral signals (clicks).

**Q: Can't you just use collaborative filtering?**  
A: CF doesn't leverage ad text semantics and fails on cold-start ads.

**Q: Is this really privacy-preserving?**  
A: More than traditional methods (no PII), but embeddings can leak info. Add DP for stronger guarantees.

**Q: What if a user clears cookies / creates new account?**  
A: Cold-start problem. Start with mean embedding, adapt after first few clicks.

**Q: How do you handle spam/malicious clicks?**  
A: Needs fraud detection layer (rate limiting, bot detection) - orthogonal to this system.

---

## ğŸŒŸ Star History

If you find this useful, please â­ the repo and cite in your work!

```bibtex
@software{privads2025,
  title={PrivAds: Privacy-First AI Advertising Platform},
  author={Your Name},
  year={2025},
  url={https://github.com/yourusername/privads}
}
```